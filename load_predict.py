# -*- coding: utf-8 -*-
"""load_predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wzkPBxlo2-d91ArKedbkx-aKiXF2DYGy

# **load_predict.py file that loads a pre-trained model and uses it to predict the category of a new resumes in pdf**

- Done by Paramesh E

## **Data Pre-Processing**
"""

# connecting with google drive
from google.colab import drive
drive.mount('/content/drive')

pip install pdfminer3

# importing library
from pdfminer.high_level import extract_text

# reading pdf folder
text = extract_text('/content/drive/MyDrive/PARAMESH_E_DATA_SCIENTIST.pdf')

# Replace new line characters with spaces
text = text.replace('\n', '')

# Replace multiple spaces with a single space
text = ' '.join(text.split())

print(text)

# Convert all strings to lowercase
text = text.lower()

# Remove numbers
text = re.sub(r'\d+','',text)

# Remove punctuation
text = text.translate(str.maketrans('','',string.punctuation))

"""# **Loading the model and Making predictions.**"""

# importing neccessary libraries to predict
import pickle
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer

# Load the pre-trained model and vectorizer
with open("/content/drive/MyDrive/Resume_screening_paramesh/model.pkl", "rb") as f:
    model = pickle.load(f)

with open("/content/drive/MyDrive/Resume_screening_paramesh/vectorizer.pkl", "rb") as f:
    vectorizer = pickle.load(f)

# printing text file
print(text)

# transforming text file
X = vectorizer.transform([text])

# Make predictions
y_pred = model.predict(X)
print("Predicted class:", y_pred[0])

y_proba

# Get probability estimates
y_proba = model.predict_proba(X)
print("Class :", y_pred[0], '\n' , "Class probability:",  y_proba[0][y_pred[0]])

"""# **Dictionary with key terms by area setup**

Resume Screening making more easier to predict with help of resume score and using visualisations 
"""

# Create dictionary with industrial and system engineering key terms by area
terms = {'Quality/Six Sigma':['black belt','capability analysis','control charts','doe','dmaic','fishbone',
                              'gage r&r', 'green belt','ishikawa','iso','kaizen','kpi','lean','metrics',
                              'pdsa','performance improvement','process improvement','quality',
                              'quality circles','quality tools','root cause','six sigma',
                              'stability analysis','statistical analysis','tqm'],      
        'Operations management':['automation','bottleneck','constraints','cycle time','efficiency','fmea',
                                 'machinery','maintenance','manufacture','line balancing','oee','operations',
                                 'operations research','optimization','overall equipment effectiveness',
                                 'pfmea','process','process mapping','production','resources','safety',
                                 'stoppage','value stream mapping','utilization'],
        'Supply chain':['abc analysis','apics','customer','customs','delivery','distribution','eoq','epq',
                        'fleet','forecast','inventory','logistic','materials','outsourcing','procurement',
                        'reorder point','rout','safety stock','scheduling','shipping','stock','suppliers',
                        'third party logistics','transport','transportation','traffic','supply chain',
                        'vendor','warehouse','wip','work in progress'],
        'Project management':['administration','agile','budget','cost','direction','feasibility analysis',
                              'finance','kanban','leader','leadership','management','milestones','planning',
                              'pmi','pmp','problem','project','risk','schedule','scrum','stakeholders'],
        'Data analytics':['analytics','api','aws','big data','busines intelligence','clustering','code',
                          'coding','data','database','data mining','data science','deep learning','hadoop',
                          'hypothesis test','iot','internet','machine learning','modeling','nosql','nlp',
                          'predictive','programming','python','r','sql','tableau','text mining',
                          'visualuzation'],
        'Healthcare':['adverse events','care','clinic','cphq','ergonomics','healthcare',
                      'health care','health','hospital','human factors','medical','near misses',
                      'patient','reporting system']}

"""# **Scores calculation per area**"""

# Initializie score counters for each area
quality = 0
operations = 0
supplychain = 0
project = 0
data = 0
healthcare = 0

# Create an empty list where the scores will be stored
scores = []

# Obtain the scores for each area
for area in terms.keys():
        
    if area == 'Quality/Six Sigma':
        for word in terms[area]:
            if word in text:
                quality +=1
        scores.append(quality)
        
    elif area == 'Operations management':
        for word in terms[area]:
            if word in text:
                operations +=1
        scores.append(operations)
        
    elif area == 'Supply chain':
        for word in terms[area]:
            if word in text:
                supplychain +=1
        scores.append(supplychain)
        
    elif area == 'Project management':
        for word in terms[area]:
            if word in text:
                project +=1
        scores.append(project)
        
    elif area == 'Data analytics':
        for word in terms[area]:
            if word in text:
                data +=1
        scores.append(data)
        
    else:
        for word in terms[area]:
            if word in text:
                healthcare +=1
        scores.append(healthcare)

"""# **scores summary**"""

# Create a data frame with the scores summary
summary = pd.DataFrame(scores,index=terms.keys(),columns=['score']).sort_values(by='score',ascending=False)
summary

"""# **Visualizing skills score using pie char to a related fields**"""

# Create pie chart visualization
pie = plt.figure(figsize=(10,10))
plt.pie(summary['score'], labels=summary.index, explode = (0.1,0,0,0,0,0), autopct='%1.0f%%',shadow=True,startangle=90)
plt.title('Industrial Engineering Candidate - Resume Decomposition by Areas')
plt.axis('equal')
plt.show()

# Save pie chart as a .png file
pie.savefig('resume_screening_results.png')